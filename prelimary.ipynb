{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastavro import parse_schema, writer\n",
    "import fastavro\n",
    "\n",
    "# Rest of your code...\n",
    "import pandas\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'record',\n",
       " 'doc': 'Spotify Wrapped Data Feed - User Interactions',\n",
       " 'name': 'com.spotify.wrapped.UserInteraction',\n",
       " 'fields': [{'name': 'id', 'type': 'long'},\n",
       "  {'logicalType': 'timestamp-millis',\n",
       "   'name': 'timestamp',\n",
       "   'type': ['string', 'null']},\n",
       "  {'name': 'action', 'type': ['string', 'null']},\n",
       "  {'name': 'song_id', 'type': ['long', 'null']},\n",
       "  {'name': 'user_id', 'type': ['long', 'null']}],\n",
       " '__fastavro_parsed': True,\n",
       " '__named_schemas': {'com.spotify.wrapped.UserInteraction': {'type': 'record',\n",
       "   'doc': 'Spotify Wrapped Data Feed - User Interactions',\n",
       "   'name': 'com.spotify.wrapped.UserInteraction',\n",
       "   'fields': [{'name': 'id', 'type': 'long'},\n",
       "    {'logicalType': 'timestamp-millis',\n",
       "     'name': 'timestamp',\n",
       "     'type': ['string', 'null']},\n",
       "    {'name': 'action', 'type': ['string', 'null']},\n",
       "    {'name': 'song_id', 'type': ['long', 'null']},\n",
       "    {'name': 'user_id', 'type': ['long', 'null']}]}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = {\n",
    "    \"doc\": \"Spotify Wrapped Data Feed - User Interactions\",\n",
    "    \"name\": \"UserInteraction\",\n",
    "    \"namespace\": \"com.spotify.wrapped\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"id\", \"type\": \"long\"},\n",
    "        {\"name\": \"timestamp\", \"type\": [\n",
    "            \"string\", \"null\"], \"logicalType\": \"timestamp-millis\"},\n",
    "        {\"name\": \"action\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"song_id\", \"type\": [\"long\", \"null\"]},\n",
    "        {\"name\": \"user_id\", \"type\": [\"long\", \"null\"]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "parsed_schema = parse_schema(schema)\n",
    "\n",
    "parsed_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'record', 'doc': 'Spotify Wrapped Data Feed - User Info', 'name': 'com.spotify.wrapped.User', 'fields': [{'name': 'user_id', 'type': 'long'}, {'name': 'username', 'type': 'string'}, {'name': 'location', 'type': 'string'}, {'logicalType': 'date', 'name': 'birthdate', 'type': 'string'}, {'symbols': ['M', 'F', 'O'], 'name': 'gender', 'type': 'string'}, {'default': [], 'name': 'favorite_genre', 'type': {'type': 'array', 'items': 'string'}}], '__fastavro_parsed': True, '__named_schemas': {'com.spotify.wrapped.User': {'type': 'record', 'doc': 'Spotify Wrapped Data Feed - User Info', 'name': 'com.spotify.wrapped.User', 'fields': [{'name': 'user_id', 'type': 'long'}, {'name': 'username', 'type': 'string'}, {'name': 'location', 'type': 'string'}, {'logicalType': 'date', 'name': 'birthdate', 'type': 'string'}, {'symbols': ['M', 'F', 'O'], 'name': 'gender', 'type': 'string'}, {'default': [], 'name': 'favorite_genre', 'type': {'type': 'array', 'items': 'string'}}]}}}\n"
     ]
    }
   ],
   "source": [
    "user_schema = {\n",
    "    \"doc\": \"Spotify Wrapped Data Feed - User Info\",\n",
    "    \"name\": \"User\",\n",
    "    \"namespace\": \"com.spotify.wrapped\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"user_id\", \"type\": \"long\"},\n",
    "        {\"name\": \"username\", \"type\": \"string\"},\n",
    "        {\"name\": \"location\", \"type\": \"string\"},\n",
    "        {\"name\": \"birthdate\", \"type\": \"string\", \"logicalType\": \"date\"},\n",
    "        {\"name\": \"gender\", \"type\": \"string\", \"symbols\": [\"M\", \"F\", \"O\"]},\n",
    "        {\"name\": \"favorite_genre\", \"type\": {\n",
    "            \"type\": \"array\", \"items\": \"string\"}, \"default\": []}\n",
    "    ]\n",
    "}\n",
    "\n",
    "parsed_user_schema = parse_schema(user_schema)\n",
    "print(parsed_user_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'record', 'doc': 'Spotify Wrapped Data Feed - Track Info', 'name': 'com.spotify.wrapped.Track', 'fields': [{'name': 'track_id', 'type': 'long'}, {'name': 'duration', 'type': 'int'}, {'name': 'artist', 'type': 'string'}], '__fastavro_parsed': True, '__named_schemas': {'com.spotify.wrapped.Track': {'type': 'record', 'doc': 'Spotify Wrapped Data Feed - Track Info', 'name': 'com.spotify.wrapped.Track', 'fields': [{'name': 'track_id', 'type': 'long'}, {'name': 'duration', 'type': 'int'}, {'name': 'artist', 'type': 'string'}]}}}\n"
     ]
    }
   ],
   "source": [
    "track_schema = {\n",
    "    \"doc\": \"Spotify Wrapped Data Feed - Track Info\",\n",
    "    \"name\": \"Track\",\n",
    "    \"namespace\": \"com.spotify.wrapped\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "            {\"name\": \"track_id\", \"type\": \"long\"},\n",
    "            {\"name\": \"duration\", \"type\": \"int\"},  # (in seconds)\n",
    "            {\"name\": \"artist\", \"type\": \"string\"}\n",
    "            #{\"name\": \"genre\", \"type\": \"string\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "parsed_track_schema = parse_schema(track_schema)\n",
    "print(parsed_track_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'name', 'popularity', 'duration_ms', 'explicit', 'artists',\n",
      "       'id_artists', 'release_date', 'danceability', 'energy', 'key',\n",
      "       'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
      "       'liveness', 'valence', 'tempo', 'time_signature'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = '/Users/yassine/Desktop/IE/4th year/2nd sem/stream analytics/datasets/tracks.csv'\n",
    "\n",
    "df_tracks_full = pd.read_csv(file_path)\n",
    "\n",
    "print(df_tracks_full.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['id', 'name', 'duration_ms', 'artists']\n",
    "df_tracks = df_tracks_full[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "no value and no default for track_id",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Open Avro output file\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.avro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m avro_output_file:\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Initialize Avro writer\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mfastavro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mavro_output_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparsed_track_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_tracks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData has been successfully populated into Avro file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32mfastavro/_write.pyx:790\u001b[0m, in \u001b[0;36mfastavro._write.writer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfastavro/_write.pyx:732\u001b[0m, in \u001b[0;36mfastavro._write.Writer.write\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfastavro/_write.pyx:459\u001b[0m, in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfastavro/_write.pyx:398\u001b[0m, in \u001b[0;36mfastavro._write.write_record\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no value and no default for track_id"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fastavro\n",
    "\n",
    "# Function to parse Avro schema\n",
    "def parse_schema(schema_json):\n",
    "    return fastavro.parse_schema(schema_json)\n",
    "\n",
    "# Define Avro schema\n",
    "track_schema = {\n",
    "    \"doc\": \"Spotify Wrapped Data Feed - Track Info\",\n",
    "    \"name\": \"Track\",\n",
    "    \"namespace\": \"com.spotify.wrapped\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"track_id\", \"type\": \"long\"},\n",
    "        {\"name\": \"duration\", \"type\": \"int\"},  # (in seconds)\n",
    "        {\"name\": \"artist\", \"type\": \"string\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Parse Avro schema\n",
    "parsed_track_schema = parse_schema(track_schema)\n",
    "\n",
    "# Replace the path with your actual file path\n",
    "file_path = '/Users/yassine/Desktop/IE/4th year/2nd sem/stream analytics/datasets/tracks.csv'\n",
    "\n",
    "# Read CSV into a DataFrame\n",
    "df_tracks_full = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_keep = ['id', 'name', 'duration_ms', 'artists']\n",
    "df_tracks = df_tracks_full[columns_to_keep]\n",
    "\n",
    "# Open Avro output file\n",
    "with open('output.avro', 'wb') as avro_output_file:\n",
    "\n",
    "    # Initialize Avro writer\n",
    "    fastavro.writer(avro_output_file, parsed_track_schema, df_tracks.to_dict(orient='records'))\n",
    "\n",
    "print(\"Data has been successfully populated into Avro file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required on field track_id",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32mfastavro/_write.pyx:433\u001b[0m, in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfastavro/_write.pyx:71\u001b[0m, in \u001b[0;36mfastavro._write.write_long\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 44\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Open Avro output file\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.avro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m avro_output_file:\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Initialize Avro writer\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mfastavro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mavro_output_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparsed_track_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_tracks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData has been successfully populated into Avro file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32mfastavro/_write.pyx:790\u001b[0m, in \u001b[0;36mfastavro._write.writer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfastavro/_write.pyx:732\u001b[0m, in \u001b[0;36mfastavro._write.Writer.write\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfastavro/_write.pyx:469\u001b[0m, in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfastavro/_write.pyx:459\u001b[0m, in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfastavro/_write.pyx:403\u001b[0m, in \u001b[0;36mfastavro._write.write_record\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfastavro/_write.pyx:468\u001b[0m, in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfastavro/_write.pyx:433\u001b[0m, in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfastavro/_write.pyx:71\u001b[0m, in \u001b[0;36mfastavro._write.write_long\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required on field track_id"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fastavro\n",
    "\n",
    "# Function to parse Avro schema\n",
    "def parse_schema(schema_json):\n",
    "    return fastavro.parse_schema(schema_json)\n",
    "\n",
    "# Define Avro schema\n",
    "track_schema = {\n",
    "    \"doc\": \"Spotify Wrapped Data Feed - Track Info\",\n",
    "    \"name\": \"Track\",\n",
    "    \"namespace\": \"com.spotify.wrapped\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"track_id\", \"type\": \"long\"},\n",
    "        {\"name\": \"duration\", \"type\": \"int\"},  # (in seconds)\n",
    "        {\"name\": \"artist\", \"type\": \"string\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Parse Avro schema\n",
    "parsed_track_schema = parse_schema(track_schema)\n",
    "\n",
    "# Replace the path with your actual file path\n",
    "file_path = '/Users/yassine/Desktop/IE/4th year/2nd sem/stream analytics/datasets/tracks.csv'\n",
    "\n",
    "# Read CSV into a DataFrame\n",
    "df_tracks_full = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_keep = ['id', 'name', 'duration_ms', 'artists']\n",
    "df_tracks = df_tracks_full[columns_to_keep]\n",
    "\n",
    "# Handle missing values in 'id' column\n",
    "df_tracks = df_tracks.dropna(subset=['id'])\n",
    "\n",
    "# Rename 'id' column to 'track_id' to match Avro schema\n",
    "df_tracks = df_tracks.rename(columns={'id': 'track_id'})\n",
    "\n",
    "# Open Avro output file\n",
    "with open('output.avro', 'wb') as avro_output_file:\n",
    "\n",
    "    # Initialize Avro writer\n",
    "    fastavro.writer(avro_output_file, parsed_track_schema, df_tracks.to_dict(orient='records'))\n",
    "\n",
    "print(\"Data has been successfully populated into Avro file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully populated into Avro file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fastavro\n",
    "\n",
    "# Function to parse Avro schema\n",
    "def parse_schema(schema_json):\n",
    "    return fastavro.parse_schema(schema_json)\n",
    "\n",
    "# Define Avro schema\n",
    "track_schema = {\n",
    "    \"doc\": \"Spotify Wrapped Data Feed - Track Info\",\n",
    "    \"name\": \"Track\",\n",
    "    \"namespace\": \"com.spotify.wrapped\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"track_id\", \"type\": \"string\"},\n",
    "        {\"name\": \"duration\", \"type\": \"int\", \"default\": 0},\n",
    "        {\"name\": \"artist\", \"type\": \"string\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Parse Avro schema\n",
    "parsed_track_schema = parse_schema(track_schema)\n",
    "\n",
    "# Replace the path with your actual file path\n",
    "file_path = '/Users/yassine/Desktop/IE/4th year/2nd sem/stream analytics/datasets/tracks.csv'\n",
    "\n",
    "# Read CSV into a DataFrame\n",
    "df_tracks_full = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_keep = ['id', 'name', 'duration_ms', 'artists']\n",
    "df_tracks = df_tracks_full[columns_to_keep]\n",
    "\n",
    "# Handle missing values in 'id' column\n",
    "df_tracks = df_tracks.dropna(subset=['id'])\n",
    "\n",
    "# Rename 'id' column to 'track_id' to match Avro schema\n",
    "df_tracks = df_tracks.rename(columns={'id': 'track_id'})\n",
    "\n",
    "# Convert 'track_id' column to string type\n",
    "df_tracks['track_id'] = df_tracks['track_id'].astype('str')\n",
    "\n",
    "# Check for and remove leading/trailing whitespaces in 'artist' column\n",
    "df_tracks['artist'] = df_tracks['artists'].str.strip()\n",
    "\n",
    "# Ensure there are no missing values in 'artist' column\n",
    "df_tracks = df_tracks.dropna(subset=['artist'])\n",
    "\n",
    "# Open Avro output file\n",
    "with open('output.avro', 'wb') as avro_output_file:\n",
    "\n",
    "    # Initialize Avro writer\n",
    "    fastavro.writer(avro_output_file, parsed_track_schema, df_tracks.to_dict(orient='records'))\n",
    "\n",
    "print(\"Data has been successfully populated into Avro file.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stream_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
